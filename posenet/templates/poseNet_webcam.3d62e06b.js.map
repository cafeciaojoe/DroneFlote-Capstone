{"version":3,"sources":["poseNet_webcam.js"],"names":["webcam_output","poseNet","poses","setup","createCanvas","createCapture","VIDEO","size","width","height","ml5","modelReady","on","results","hide","select","html","draw","image","drawKeypoints","drawSkeleton","i","length","pose","j","keypoints","keypoint","score","fill","noStroke","ellipse","position","x","y","skeleton","startPoint","endPoint","stroke","line"],"mappings":";AAaA,IAAIA,EAEAC,EAEAC,EAAQ,GAMZ,SAASC,IAMPC,aAAa,IAAK,MAGlBJ,EAAgBK,cAAcC,QAEhBC,KAAKC,MAAOC,SAM1BR,EAAUS,IAAIT,QAAQD,EAAeW,IAS7BC,GAAG,OAAQ,SAASC,GAC1BX,EAAQW,IAOVb,EAAcc,OAOhB,SAASH,IACPI,OAAO,WAAWC,KAAK,gBAQzB,SAASC,IAGPC,MAAMlB,EAAe,EAAG,EAAGQ,MAAOC,QAGlCU,IAEAC,IAIF,SAASD,IAKF,IAAA,IAAIE,EAAI,EAAGA,EAAInB,EAAMoB,OAAQD,IAAK,CAEjCE,IAAAA,EAAOrB,EAAMmB,GAAGE,KACf,IAAA,IAAIC,EAAI,EAAGA,EAAID,EAAKE,UAAUH,OAAQE,IAAK,CAE1CE,IAAAA,EAAWH,EAAKE,UAAUD,GAE1BE,EAASC,MAAQ,KAEnBC,KAAK,EAAG,EAAG,KAEXC,WAOAC,QAAQJ,EAASK,SAASC,EAAGN,EAASK,SAASE,EAAG,GAAI,OAO9D,SAASb,IAMF,IAAA,IAAIC,EAAI,EAAGA,EAAInB,EAAMoB,OAAQD,IAAK,CACjCa,IAAAA,EAAWhC,EAAMmB,GAAGa,SAEnB,IAAA,IAAIV,EAAI,EAAGA,EAAIU,EAASZ,OAAQE,IAAK,CAEpCW,IAAAA,EAAaD,EAASV,GAAG,GAEzBY,EAAWF,EAASV,GAAG,GAE3Ba,OAAO,EAAG,IAAK,GAOfC,KAAKH,EAAWJ,SAASC,EAAGG,EAAWJ,SAASE,EAAGG,EAASL,SAASC,EAAGI,EAASL,SAASE","file":"poseNet_webcam.3d62e06b.js","sourceRoot":"..","sourcesContent":["// Copyright (c) 2018 ml5\n//\n// This software is released under the MIT License.\n// https://opensource.org/licenses/MIT\n\n/*\n Human pose detection using machine learning.\n This code uses: \n    ML5.js: giving us easy to use poseNet ML model.\n    P5.js: for drawing and creating video output in the browser.\n*/\n\n// the output of our webcam\nlet webcam_output;\n// to store the ML model\nlet poseNet;\n// output of our ML model is stores in this\nlet poses = [];\n\n/* function setup() is by P5.js:\n      it is the first function that is executed and runs only once.\n      We will do our initial setup here.\n*/\nfunction setup() {\n\n  /* create a box in browser to show our output. Canvas having:\n         width: 640 pixels and\n         height: 480 pixels\n  */\n  createCanvas(640, 480);\n\n  // get webcam input\n  webcam_output = createCapture(VIDEO);\n  // set webcam video to the same height and width of our canvas\n  webcam_output.size(width, height);\n\n  /* Create a new poseNet model. Input:\n      1) give our present webcam output\n      2) a function \"modelReady\" when the model is loaded and ready to use\n  */\n  poseNet = ml5.poseNet(webcam_output, modelReady);\n\n  /*\n    An event or trigger.\n    Whenever webcam gives a new image, it is given to the poseNet model.\n    The moment pose is detected and output is ready it calls:\n    function(result): where result is the models output.\n    store this in poses variable for furthur use.\n  */\n  poseNet.on('pose', function(results) {\n    poses = results;\n  });\n\n  /* Hide the webcam output for now.\n     We will modify the images and show with points and lines of the \n     poses detected later on.\n  */\n  webcam_output.hide();\n}\n\n/* function called when the model is ready to use.\n   set the #status field to Model Loaded for the\n  user to know we are ready to rock!\n */\nfunction modelReady() {\n  select('#status').html('Model Loaded');\n}\n\n\n/* function draw() is by P5.js:\n      This function is called on repeat forever (unless you plan on closing the browser\n      and/or pressing the power button)\n*/\nfunction draw() {\n\n  // show the image we currently have of the webcam output.\n  image(webcam_output, 0, 0, width, height);\n\n  // draw the points we have got from the poseNet model\n  drawKeypoints();\n  // draw the lines too.\n  drawSkeleton();\n}\n\n// A function to draw detected points on the image.\nfunction drawKeypoints(){\n  /*\n    Remember we saved all the result from the poseNet output in \"poses\" array.\n    Loop through every pose and draw keypoints\n   */\n  for (let i = 0; i < poses.length; i++) {\n    // For each pose detected, loop through all the keypoints\n    let pose = poses[i].pose;\n    for (let j = 0; j < pose.keypoints.length; j++) {\n      // A keypoint is an object describing a body part (like rightArm or leftShoulder)\n      let keypoint = pose.keypoints[j];\n      // Only draw an ellipse if the pose probability is bigger than 0.2\n      if (keypoint.score > 0.2) {\n        // choosing colour. RGB where each colour ranges from 0 255\n        fill(0, 0, 255);\n        // disable drawing outline\n        noStroke();\n        /* draw a small ellipse. Which being so small looks like a dot. Purpose complete.\n            input: X position of the point in the 2D image\n                   Y position as well\n                   width in px of the ellipse. 10 given\n                   height in px of the ellipse. 10 given\n        */\n        ellipse(keypoint.position.x, keypoint.position.y, 10, 10);\n      }\n    }\n  }\n}\n\n// A function to draw the skeletons\nfunction drawSkeleton() {\n    /*\n    Remember we saved all the result from the poseNet output in \"poses\" array.\n    Loop through every pose and draw skeleton lines.\n   */\n  // Loop through all the skeletons detected\n  for (let i = 0; i < poses.length; i++) {\n    let skeleton = poses[i].skeleton;\n    // For every skeleton, loop through all body connections\n    for (let j = 0; j < skeleton.length; j++) {\n      // line start point\n      let startPoint = skeleton[j][0];\n      // line end point\n      let endPoint = skeleton[j][1];\n      // Sets the color used to draw lines and borders around shapes\n      stroke(0, 255, 0);\n      /* draw a line:\n            input: X position of start point of line in this 2D image\n                   Y position as well\n                   X position of end point of line in this 2D image\n                   Y position as well\n          */\n      line(startPoint.position.x, startPoint.position.y, endPoint.position.x, endPoint.position.y);\n    }\n  }\n}\n"]}